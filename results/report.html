<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Anshi Arora, Owen Philliber, James San, Samantha Su">
<meta name="dcterms.date" content="2024-10-30">

<title>Biomarkers of ASD</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="report_files/libs/clipboard/clipboard.min.js"></script>
<script src="report_files/libs/quarto-html/quarto.js"></script>
<script src="report_files/libs/quarto-html/popper.min.js"></script>
<script src="report_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="report_files/libs/quarto-html/anchor.min.js"></script>
<link href="report_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="report_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="report_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="report_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="report_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="report_files/libs/quarto-diagram/mermaid.min.js"></script>
<script src="report_files/libs/quarto-diagram/mermaid-init.js"></script>
<link href="report_files/libs/quarto-diagram/mermaid.css" rel="stylesheet">


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Biomarkers of ASD</h1>
<p class="subtitle lead">Group 10</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Anshi Arora, Owen Philliber, James San, Samantha Su </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Updated</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 30, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="abstract" class="level2">
<h2 class="anchored" data-anchor-id="abstract">Abstract</h2>
<p>Our analysis of the ASD biomarker data set expands on the Hewitson et al.(2021) paper by evaluating the impact of log and outlier transformations on the data, exploring how variations in the original methodology affect the resulting core protein panel, and attempting to improve the classification model proposed in the research article. In the context of this dataset, this involves finding proteins that are predictors, or biomarkers, of Autism Spectrum Disorder. The goal of the analysis to explore various classification methods and modifications that improve their efficacy. In reference to the preproccesing of the biomarker dataset, we use graphics and statistical testing to show how log transformations of the protein levels make the data more normal and quantify the difference between the occurrence of outliers in TD vs.&nbsp;ASD subjects. Moving onto the methodology, we find that splitting the dataset into training and testing, using a larger panel size, and utilizing a fuzzy (rather than a hard) intersection does not necessarily improve the accuracy of the model. Finally, we use a stepwise regression approach to improve the classification methodology in the previous task by finding a simpler method that maintains the same accuracy. Using both forwards and backwards selection, we find a panel of 6 proteins that produces similar AIC and deviance scores to the full model. This, thereby, improves the simplicity of the classifier without sacrificing its validity.</p>
</section>
<section id="dataset" class="level2">
<h2 class="anchored" data-anchor-id="dataset">Dataset</h2>
<p>The data was gathered from Hewitson et al.&nbsp;(2021). In total the data set consists of 154 male participants of whom 76 have ASD, mean age of 5.6 years, and the other 78 are typically developing boys, mean age of 5.7 years, with ages ranging from 18 months to 8 years of age. In terms of demographics, both ASD and TD groups had majority White/Caucasian with 45.2% and 51.9% respectively while Asian or Pacific Islander made up the minority with 2.6% and 3.9%. Moreover, a majority of boys reported no comorbidities, 52.8% and 75.3%, however seasonal allergies followed with 41.7% of ASD boys and 22.4% of TD boys. For medications attribute “none” was also the majority having 92% of ASD boys and 97.4% of TD boys falling into this attribute, other medications were too few in representation. On top of this, ASD boys specifically went through ADOS testing which measures ASD symptom severity between 6 and 23, 23 being the most severe, and TD boys went through ABAS-II testing to ensure there were no developmental concerns.</p>
<p>With our overarching goal to identify a panel of proteins that correlated as a blood biomarker for detecting ASF early, the data required a way to gather serum levels of proteins, thus each participant underwent blood draws utilizing serum separation tubes. A total of 1,317 proteins were identified and 1,125 analyzed after 192 proteins failed quality control. For data preprocessing, protein data was log-transformed, center and scaled, and trimmed. This way the data would be standardized and normalized, trimming allowed us to take note of outliers, values less than -3 or greater than 3 were considered outliers. Our data is now ready for testing to find the top predictive proteins.</p>
</section>
<section id="summary-of-published-analysis" class="level2">
<h2 class="anchored" data-anchor-id="summary-of-published-analysis">Summary of published analysis</h2>
<p>After collecting the data, the data was then cleaned by removing proteins that did not pass quality control, normalized through a log10 transform and then a z-transformation, and then values greater than 3 and less than -3 were clipped to 3 and -3. The clipping was to prevent outliers from influencing the analysis.</p>
<p>After the data was cleaned, the paper then used 3 different methods to evaluate the importance of each protein to ASD. The three methods are the correlation coefficients, T-tests, and random forests. The correlation coefficients were found by calculating the correlation between each protein and the ADOS scores. The top 10 proteins with the largest absolute value correlation coefficient were identified. The T test method was used to determine if the mean level of each protein from group of ASD subjects was significantly different from the mean level of the TD subjects. The top 10 proteins from this method were identified through the tests that had the highest significance. Finding the most significant proteins from random forests relies on boosting decision trees to create a large amount of trees. Keeping track of which proteins were used most often can signify how important that protein is to predicting ASD. Thus the 10 proteins with the highest averaged importance index were identified.</p>
<p>After finding the top 10 proteins for each of the methods, any protein that was in the top 10 for all 3 methods was classified as a ‘core’ protein. There were 5 proteins that the paper found measured in the top 10 for all 3 methods and 13 others that were in either 1 or 2 methods top 10 list. In order to determine if any of the 13 other proteins were important they created logistic regressions with the 5 ‘core’ proteins and added on of the 13 other proteins at a time. The metric the paper used to determined if the protein was important to ASD was if the logistic regression ROC increased by a significant amount. From this, they identified 4 more proteins to be significant in determining ASD. The 9 proteins that the paper suggests are the optimal proteins to identify ASD are the 5 ‘core’ proteins, mitogen-activated protein kinase 14 (MAPK14), immunoglobulin D (IgD), dermatopontin (DERM), ephrin type-B receptor 2 (EPHB2) and soluble urokinase-type plasminogen activator receptor (suPAR) along with the 4 additional proteins, receptor tyrosine kinase-like orphan receptor 1 [ROR1], platelet receptor Gl24 [GI24], eukaryotic translation initiation factor 4H [elF-4H], and arylsulfatase B [ARSB]. The logistic regression with these proteins resulted in an AUC score of 0.860, a sensitivity of 0.833 and a specificity of 0.846.</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD
    A[Collect Data] --&gt; |Clean the Data|B{Apply Variable Selection Methods}
    B --&gt; |One| C[Correlation Coefficients]
    B--&gt;|Two| D[T Test]
    B --&gt; |Three| F[Random Forest]
    C --&gt; G[Take Top 10 Most Important Protiens]
    D --&gt; G
    F --&gt; G
    G --&gt; I[See if Proteins that are in a Top 10 &lt;br&gt; List Improve the ROC curve]
    G --&gt; H[Proteins That are in All &lt;br&gt; Three Lists are Important]
    I --&gt; |If They Do|J[Classify Them as Important]
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</section>
<section id="findings" class="level2">
<h2 class="anchored" data-anchor-id="findings">Findings</h2>
<section id="impact-of-preprocessing-and-outliers" class="level3">
<h3 class="anchored" data-anchor-id="impact-of-preprocessing-and-outliers">Impact of preprocessing and outliers</h3>
<section id="question-1-impact-of-log-transformation" class="level5">
<h5 class="anchored" data-anchor-id="question-1-impact-of-log-transformation">Question 1: Impact of log transformation</h5>
<p>In order to investigate the role of the log transformation in the preprocessing of our biomarker data, we will first look at the distribution of raw values for a sample of proteins.</p>
<p>First, we randomly sampled 5 proteins from the raw dataset. The proteins sampled were PGRP-S, PACAP-27, TRAIL R4, IGFBP-1, cIAP-2.</p>
<p>The distributions of the protein levels for these 5 proteins are shown below.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="report_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>As we can see, the distributions do not seem normal as many of them are skewed to the left and do not seem centered around a mean. We can use qqplots for each of these proteins to support this conclusion. These are shown below:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="report_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>As shown above, a lot of the protein level distributions for our sample of 5 proteins do not follow the qqline shown in red for each above qq-plot. To determine if they significantly stray away from a normal distribution, we can use Shapiro-Wilk Tests.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5 × 3
  protein      pval normal
  &lt;chr&gt;       &lt;dbl&gt; &lt;lgl&gt; 
1 IGFBP-1  2.61e- 2 FALSE 
2 PACAP-27 1.04e-24 FALSE 
3 PGRP-S   1.68e-23 FALSE 
4 TRAIL R4 9.77e-21 FALSE 
5 cIAP-2   1.06e-22 FALSE </code></pre>
</div>
</div>
<p>The tests with p-values smaller than our alpha of 0.05 indicate that we should reject the null hypothesis that the distributions of the levels for these proteins is normal. As shown above, all proteins failed the normality test.</p>
<p>This is why the log transformation is required. Below, we once again generate distribution histograms and qq-plots for each protein. However, this time we use the log transformed data for these proteins from the biomarker_clean dataset.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="report_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>As we can see above, compared to the original protein level distributions for these proteins, the distributions look much closer to the normal distribution</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="report_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The qq-plots also look much more representative of normal distributions after the log transformation.</p>
</section>
<section id="question-2-impact-of-outliers" class="level5">
<h5 class="anchored" data-anchor-id="question-2-impact-of-outliers">Question 2: Impact of outliers</h5>
<div class="cell">
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<colgroup>
<col style="width: 6%">
<col style="width: 15%">
<col style="width: 14%">
<col style="width: 12%">
<col style="width: 13%">
<col style="width: 16%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">group</th>
<th style="text-align: right;">TotalOutliers</th>
<th style="text-align: right;">OutliersMean</th>
<th style="text-align: right;">OutilersSD</th>
<th style="text-align: right;">OutliersMax</th>
<th style="text-align: right;">OutlierNumbers</th>
<th style="text-align: right;">NonOutlierNumbers</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">ASD</td>
<td style="text-align: right;">1007</td>
<td style="text-align: right;">13.25000</td>
<td style="text-align: right;">19.81994</td>
<td style="text-align: right;">126</td>
<td style="text-align: right;">75</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;">TD</td>
<td style="text-align: right;">1372</td>
<td style="text-align: right;">17.58974</td>
<td style="text-align: right;">29.24657</td>
<td style="text-align: right;">157</td>
<td style="text-align: right;">77</td>
<td style="text-align: right;">1</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>As we can see by the data frame, of the 76 subjects with ASD, 75 of them had at least one protein above the threshold. Similarly, the TD group had 77 out of the 78 subjects to have at least one protein above the threshold. In these subjects, there are a total of 1007 proteins that are above the threshold in the ASD group and 1372 total proteins that are above the threshold in the TD group. This means that a ASD subject has on average 13.25 proteins that were trimmed off, when TD subjects had on average around 17.59 proteins that were outliers. Thus, outliers are more frequent in subjects in the TD group than the ASD group.</p>
</section>
</section>
<section id="methodological-variations" class="level3">
<h3 class="anchored" data-anchor-id="methodological-variations">Methodological variations</h3>
<p>We looked at the following three modifications to the methodology and evaluated how each impacted the results.</p>
<section id="modification-1" class="level5">
<h5 class="anchored" data-anchor-id="modification-1">Modification 1:</h5>
<p>Repeat the analysis but carry out the entire selection procedure on a training partition (set aside some testing data at the very beginning and don’t use it until you are evaluating accuracy at the very end)</p>
<p>We used a proportion of 0.8 to divide our dataset into training and testing sets with 80% of the units being assigned to the training set.</p>
<p>How are the results affected by this modification: By setting aside testing data at the start, we ensure that the evaluation is more accurate and unbiased, as the model and feature selection are based solely on the training data. This also ensures that the accuracy isn’t falsely inflated as the data that the model is tested on is not the same as the data it was trained on.</p>
</section>
<section id="modification-2" class="level5">
<h5 class="anchored" data-anchor-id="modification-2">Modification 2:</h5>
<p>Choose a larger number (more than ten) of top predictive proteins using each selection method</p>
<p>For both the t-test and random forest selection methods, we used the top 20 proteins based on their significance or importance scores.</p>
<p>How are the results affected by this modification: Increasing the number of proteins used as features can allow the model to capture more variance in the data, which may improve the predictive accuracy.</p>
</section>
<section id="modification-3" class="level5">
<h5 class="anchored" data-anchor-id="modification-3">Modification 3:</h5>
<p>Use a fuzzy intersection instead of a hard intersection to combine the sets of top predictive proteins across selection methods</p>
<p>We determined the intersection by finding the top 20 proteins with the greatest predictive rank in the union between the panels found through t-tests and random forest.</p>
<p>How are the results affected by this modification: This increases flexibility by allowing proteins that are significant in only one method but rank highly to contribute to the model.</p>
</section>
<section id="evaluating-these-modifications" class="level5">
<h5 class="anchored" data-anchor-id="evaluating-these-modifications">Evaluating these modifications</h5>
<p>The panel of 20 proteins generated from applying the t-test method on the training data is shown below:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code> [1] "DERM"                  "IgD"                   "TSP4"                 
 [4] "C1QR1"                 "MRC2"                  "PTN"                  
 [7] "FSTL1"                 "Calcineurin"           "RELT"                 
[10] "RET"                   "Cadherin-5"            "MIA"                  
[13] "TFF3"                  "PEDF"                  "ROR1"                 
[16] "Fas, soluble"          "Coagulation Factor IX" "suPAR"                
[19] "STRATIFIN"             "MATN2"                </code></pre>
</div>
</div>
<p>The panel of 20 proteins generated from applying the random forest method on the training data is shown below:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code> [1] "DERM"                      "eIF-4H"                   
 [3] "IgD"                       "M2-PK"                    
 [5] "TSP4"                      "MAPK14"                   
 [7] "ALCAM"                     "CK-MB"                    
 [9] "CSK"                       "MRC2"                     
[11] "SRCN1"                     "Notch 1"                  
[13] "C1QR1"                     "14-3-3 protein zeta/delta"
[15] "PPID"                      "PEDF"                     
[17] "PTN"                       "ILT-4"                    
[19] "EGFRvIII"                  "RGM-C"                    </code></pre>
</div>
</div>
<p>Using a fuzzy intersection (based on the predictive rank of the proteins) to merge these 2 panels into a group of 20 core proteins, this final panel is shown below:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code> [1] "DERM"        "IgD"         "TSP4"        "MRC2"        "C1QR1"      
 [6] "PTN"         "eIF-4H"      "M2-PK"       "MAPK14"      "FSTL1"      
[11] "ALCAM"       "Calcineurin" "CK-MB"       "RELT"        "PEDF"       
[16] "CSK"         "RET"         "Cadherin-5"  "SRCN1"       "MIA"        
[21] "Notch 1"    </code></pre>
</div>
</div>
<p>We can now evaluate the accuracy of this modified panel to see if these methodological variances made a difference. This will be done through a logistic regression like the initial panel. However, it will be performed on the test group that we separated out in Modification 1. The metrics for our logisitic regression are shown below:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 4 × 3
  .metric     .estimator .estimate
  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;
1 sensitivity binary         0.75 
2 specificity binary         0.333
3 accuracy    binary         0.571
4 roc_auc     binary         0.333</code></pre>
</div>
</div>
<p>As we can see the accuracy is low. This is lower than the accuracy generated by the in-class analysis which was 0.7532. This may be due to the fact that we are using a separate test set and not classifying the same data that was used to train the model. It may also be caused by the fuzzy intersection or larger panel, which may be allowing unnecessary predictor proteins to decrease the accuracy of the model.</p>
</section>
</section>
<section id="improved-classifier" class="level3">
<h3 class="anchored" data-anchor-id="improved-classifier">Improved classifier</h3>
<p>To improve a classifier, a model can be either simplified while still achieving the a similar accuracy or can be made more complicated to achieve a better accuracy. This is because the Occam’s razor principle suggests that when choosing between models, the simpler model is better assuming that it achieves the same accuracy. Thus we decided to simplify our model from task 3. Our approach to simplifying the model was through stepwise regression. Stepwise regression is adding or removing parameters for a logistic regression based on a criterion until adding any of the remaining parameter does not significantly improve our glm or removing any parameter worsens our model. The criterion we used was AIC which is calculated using the number of independent variables and the maximum likelihood estimate of the model to determine if the increase in variables produces a better model. We deployed forwards selection, which only adds variables, backwards selection, which only removes variables, and both, which can add and remove variables. We identified our “best” proteins as the proteins that were in 2 or 3 of the stepwise regressions. The 6 proteins that achieved this are, DERM, IgD, PTN, RELT, CSK and 14-3-3 protein theta.</p>
<section id="the-summary-of-the-forwards-model" class="level4">
<h4 class="anchored" data-anchor-id="the-summary-of-the-forwards-model">The Summary of the Forwards Model</h4>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = class ~ DERM + `M2-PK` + IgD + SRCN1 + FSTL1 + 
    PEDF + PTN, family = binomial, data = biomarker_sstar)

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -0.06722    0.22433  -0.300 0.764449    
DERM        -0.81902    0.33462  -2.448 0.014381 *  
`M2-PK`     -0.88419    0.26189  -3.376 0.000735 ***
IgD         -1.01087    0.26151  -3.866 0.000111 ***
SRCN1       -0.87685    0.28039  -3.127 0.001765 ** 
FSTL1       -0.54878    0.30302  -1.811 0.070130 .  
PEDF        -0.66082    0.29090  -2.272 0.023106 *  
PTN         -0.54863    0.34126  -1.608 0.107908    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 213.46  on 153  degrees of freedom
Residual deviance: 123.45  on 146  degrees of freedom
AIC: 139.45

Number of Fisher Scoring iterations: 6</code></pre>
</div>
</div>
</section>
<section id="the-summary-fo-the-backwards-model" class="level4">
<h4 class="anchored" data-anchor-id="the-summary-fo-the-backwards-model">The Summary fo the Backwards Model</h4>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = class ~ DERM + IgD + PTN + `M2-PK` + MAPK14 + Calcineurin + 
    PEDF + SRCN1 + `Notch 1`, family = binomial, data = biomarker_sstar)

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  -0.1296     0.2297  -0.564  0.57274    
DERM         -0.7111     0.3493  -2.036  0.04177 *  
IgD          -1.2256     0.2934  -4.177 2.96e-05 ***
PTN          -0.5840     0.3626  -1.610  0.10733    
`M2-PK`      -0.9637     0.3198  -3.013  0.00259 ** 
MAPK14        0.6028     0.4058   1.485  0.13742    
Calcineurin  -0.5628     0.3709  -1.518  0.12913    
PEDF         -0.7435     0.2910  -2.555  0.01061 *  
SRCN1        -1.0756     0.3456  -3.112  0.00186 ** 
`Notch 1`    -0.6785     0.4332  -1.566  0.11735    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 213.46  on 153  degrees of freedom
Residual deviance: 119.88  on 144  degrees of freedom
AIC: 139.88

Number of Fisher Scoring iterations: 6</code></pre>
</div>
</div>
</section>
<section id="the-summary-of-the-forwards-and-backwards-model" class="level4">
<h4 class="anchored" data-anchor-id="the-summary-of-the-forwards-and-backwards-model">The Summary of the Forwards and Backwards Model</h4>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = class ~ DERM + IgD + PTN + `M2-PK` + MAPK14 + Calcineurin + 
    PEDF + SRCN1 + `Notch 1`, family = binomial, data = biomarker_sstar)

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  -0.1296     0.2297  -0.564  0.57274    
DERM         -0.7111     0.3493  -2.036  0.04177 *  
IgD          -1.2256     0.2934  -4.177 2.96e-05 ***
PTN          -0.5840     0.3626  -1.610  0.10733    
`M2-PK`      -0.9637     0.3198  -3.013  0.00259 ** 
MAPK14        0.6028     0.4058   1.485  0.13742    
Calcineurin  -0.5628     0.3709  -1.518  0.12913    
PEDF         -0.7435     0.2910  -2.555  0.01061 *  
SRCN1        -1.0756     0.3456  -3.112  0.00186 ** 
`Notch 1`    -0.6785     0.4332  -1.566  0.11735    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 213.46  on 153  degrees of freedom
Residual deviance: 119.88  on 144  degrees of freedom
AIC: 139.88

Number of Fisher Scoring iterations: 6</code></pre>
</div>
</div>
</section>
<section id="plots-of-the-residuals-for-each-model" class="level4">
<h4 class="anchored" data-anchor-id="plots-of-the-residuals-for-each-model">Plots of the Residuals for each Model</h4>
<p><code>{r{}} par(mfrow = c(2, 2)) plot(forward_model$residuals, main = "Forward Residuals", ylab = "Residuals") plot(backward_model$residuals, main = "Backward Residuals", ylab = "Residuals") plot(both_model$residuals, main = "Both-Direction Residuals", ylab = "Residuals")</code></p>
<p>Comparing the logistic regression with all 20 core proteins and our simpler model, we find that our model has a residual deviance of 130.74 when the full model only has a residual deviance of 119.37. Similarly, the AIC for the reduced model is 144.74, when the full model obtains an AIC of 161.37. Since the model is able to produce similar AIC and deviances and is a simpler model, we suggest that our panel of 6 proteins is superior to the 20 proteins we found in task 3.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Deviance Table

Model 1: class ~ DERM + IgD + TSP4 + MRC2 + C1QR1 + PTN + `eIF-4H` + `M2-PK` + 
    MAPK14 + FSTL1 + ALCAM + Calcineurin + `CK-MB` + RELT + PEDF + 
    CSK + RET + `Cadherin-5` + SRCN1 + MIA + `Notch 1`
Model 2: class ~ DERM + IgD + PTN + RELT + CSK
  Resid. Df Resid. Dev  Df Deviance
1       132     114.01             
2       148     138.77 -16  -24.753</code></pre>
</div>
</div>
</section>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>