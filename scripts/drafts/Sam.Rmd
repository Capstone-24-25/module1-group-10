---
title: "Untitled"
author: "Samantha Su"
date: "2024-10-29"
output: html_document
---
1. What do you imagine is the reason for log-transforming the protein levels in biomarker-raw.csv? (Hint: look at the distribution of raw values for a sample of proteins.)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd('/Users/sammysu/Downloads')
biomarker_raw<-read.csv("biomarker-raw.csv")
protein_levels<-biomarker_raw[, sapply(biomarker_raw, is.numeric)]
library(ggplot2)
all_protein_levels <- unlist(protein_levels, use.names = FALSE)
```

```{r}
Protein_Hist<-ggplot(data.frame(Protein_Level = all_protein_levels), aes(x = Protein_Level)) +
  geom_histogram(bins = 30, color = "black", fill = "lightblue") +
  labs(title = "Distribution of Protein Levels", x="Protein Level", y="Frequency") +
  theme_minimal()
Protein_Hist
```

This histogram shows that the protein levels are very right-skewed in their raw form. Therefore, we need to conduct a log transformation to normalize the data, reduce the influence of extreme values, and make it more suitable for statistical analysis.

3. Experiment with the following modifications:

-repeat the analysis but carry out the entire selection procedure on a training partition -- in other words, set aside some testing data at the very beginning and don't use it until you are evaluating accuracy at the very end.

```{r}
library(tidyverse)
library(infer)
library(randomForest)
library(tidymodels)
library(modelr)
library(yardstick)

setwd('/Users/sammysu/Downloads')
trim <- function(x, .at){
  x[abs(x) > .at] <- sign(x[abs(x) > .at])*.at
  return(x)
}

var_names <- read_csv("biomarker-raw.csv", col_names = F, n_max = 2, col_select = -(1:2)) %>%
  t() %>%
  as_tibble() %>%
  rename(name = V1, abbreviation = V2) %>%
  na.omit()

biomarker_data <- read_csv("biomarker-raw.csv", skip = 2, col_select = -2L,
                           col_names = c('group', 'empty', pull(var_names, abbreviation), 'ados'),
                           na = c('-', '')) %>%
  filter(!is.na(group)) %>%
  mutate(across(.cols = -c(group, ados), ~ trim(scale(log10(.x))[, 1], .at = 3))) %>%
  select(group, ados, everything())

set.seed(101422)
biomarker_split <- initial_split(biomarker_data, prop = 0.8)
biomarker_train <- training(biomarker_split)
biomarker_test <- testing(biomarker_split)
```
How are the results affected by this modification: By setting aside testing data at the start, we ensure that the evaluation is more accurate and unbiased, as the model and feature selection are based solely on the training data.

-choose a larger number (more than ten) of top predictive proteins using each selection method

top 20 predictive proteins

```{r}
proteins_s1 <- ttests_out %>%
  slice_min(p.adj, n = 20) %>%
  pull(protein)
predictors <- biomarker_train %>% select(-c(group, ados))
response <- biomarker_train %>% pull(group) %>% factor()

set.seed(101422)
rf_out <- randomForest(x = predictors, y = response, ntree = 1000, importance = TRUE)

proteins_s2 <- rf_out$importance %>% 
  as_tibble() %>%
  mutate(protein = rownames(rf_out$importance)) %>%
  slice_max(MeanDecreaseGini, n = 20) %>%
  pull(protein)
```

How are the results affected by this modification: Increasing the number of proteins used as features can allow the model to capture more variance in the data, which may improve the predictive accuracy.

-use a fuzzy intersection instead of a hard intersection to combine the sets of top predictive proteins across selection methods

```{r}
protein_union <- union(proteins_s1, proteins_s2)
ranked_proteins <- tibble(
  protein = protein_union,
  rank_s1 = match(protein_union, proteins_s1, nomatch = 21),
  rank_s2 = match(protein_union, proteins_s2, nomatch = 21)
) %>%
  mutate(total_rank = rowMeans(across(starts_with("rank")), na.rm = TRUE)) %>%
  arrange(total_rank) %>%
  slice_min(total_rank, n = 20) %>%
  pull(protein)
```

How are the results affected by this modification: This increases flexibility by allowing proteins that are significant in only one method but rank highly to contribute to the model.